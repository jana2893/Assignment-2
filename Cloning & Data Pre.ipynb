{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5405974f",
   "metadata": {},
   "source": [
    "# <b><div style='padding:25px;background-color:#9B2335;color:white;border-radius:4px;font-size:100%;text-align: center'>Phonepe Pulse Data Visualization and Exploration <br><br>  A User-Friendly Tool Using Streamlit and Plotly</div></b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0985e9a",
   "metadata": {},
   "source": [
    "## <p style=\"padding:25px;background-color:#DFCFBE;color:black;text-align: center\"> &#128218; Importing required libraries </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb41c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gitdb\n",
    "import pandas as pd\n",
    "import os\n",
    "from gitdb import git\n",
    "from git import Repo\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a55de34",
   "metadata": {},
   "source": [
    "## <p style=\"padding:25px;background-color:#55B4B0;color:black;text-align: center\"> &#128260; Cloning from pule repository </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clonerepo(repo_link,local_path):\n",
    "    repo_name=os.path.join(local_path, os.path.basename(repo_link).removesuffix('.git').title())\n",
    "    repo_path=os.path.join(local_path, repo_name)\n",
    "    local_dir = os.path.join(repo_path, 'data')\n",
    "    last_part = repo_name.split('\\\\')[-1]\n",
    "    \n",
    "    if os.path.exists(repo_path) and os.path.isdir(repo_path) and os.path.exists(os.path.join(repo_path, '.git')):\n",
    "        print(f\"Cloning repository '{last_part}'... \")\n",
    "        print(f\"Repository '{last_part}' already exists. Skipping cloning.\")\n",
    "    else:\n",
    "        print(f\"Cloning repository '{last_part}'... \")\n",
    "        Repo.clone_from(repo_link, repo_path)\n",
    "        print(f\"Repository '{last_part}' cloned successfully.\")\n",
    "    return local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec31a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_link=\"https://github.com/PhonePe/pulse.git\"\n",
    "local_path = r'E:\\Technology\\Python Project\\Clone'\n",
    "\n",
    "\n",
    "local_dir = clonerepo(repo_link,local_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f002c01",
   "metadata": {},
   "source": [
    "## <p style=\"color:#FEC260\">&#128736;  Refining State names </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(local_dir):\n",
    "    for root, dirs, files in os.walk(local_dir):\n",
    "        if 'state' in dirs:\n",
    "            state_dir = os.path.join(root, 'state')\n",
    "            for state_folder in os.listdir(state_dir):\n",
    "                # rename the state folder\n",
    "                old_path = os.path.join(state_dir, state_folder)\n",
    "                new_path = os.path.join(state_dir, state_folder.title().replace('-', ' ').replace('&', 'and'))\n",
    "                os.rename(old_path, new_path)\n",
    "    print(\"Renamed all sub-directories successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f6218",
   "metadata": {},
   "source": [
    "## <p style=\"color:#FEC260\"> &#128193; Getting all State folder root</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe23d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_state_paths(local_dir):\n",
    "    path_list = []\n",
    "    for root, dirs, files in os.walk(local_dir):\n",
    "        if os.path.basename(root) == 'state':\n",
    "            path_list.append(root.replace('\\\\', '/'))\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d326cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dir = extract_state_paths(local_dir)\n",
    "state_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21ae1aa",
   "metadata": {},
   "source": [
    "## <p style=\"color:#FEC260\"> &#128202; Creating Data Frame using the cloned data </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17fcc8e",
   "metadata": {},
   "source": [
    "### <p style=\"color:#F2F7A1\"> 1. Aggregate Transaction </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98b2e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_path=state_dir[0]\n",
    "state_list = os.listdir(state_path)\n",
    "agg_tran_dict = {'State': [], \n",
    "                 'Year': [], \n",
    "                 'Quarter': [], \n",
    "                 'Transaction_type': [],\n",
    "                 'Transaction_count': [], \n",
    "                 'Transaction_amount': []\n",
    "                 }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        qtr_path= year_path + '/' + year + '/'\n",
    "        qtr_list = os.listdir(qtr_path)\n",
    "        \n",
    "        for qtr in qtr_list:\n",
    "            json_path = qtr_path + qtr\n",
    "            df = pd.read_json(json_path)\n",
    "\n",
    "            for i in df['data']['transactionData']:\n",
    "                type = i['name']\n",
    "                count = i['paymentInstruments'][0]['count']\n",
    "                amount = i['paymentInstruments'][0]['amount']\n",
    "                \n",
    "                agg_tran_dict['State'].append(state.replace(' And ',' and '))\n",
    "                agg_tran_dict['Year'].append(year)\n",
    "                agg_tran_dict['Quarter'].append(int(qtr[0]))\n",
    "                agg_tran_dict['Transaction_type'].append(type)\n",
    "                agg_tran_dict['Transaction_count'].append(count)\n",
    "                agg_tran_dict['Transaction_amount'].append(amount)\n",
    "agg_tran_df = pd.DataFrame(agg_tran_dict)\n",
    "agg_tran_df                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f6c0b",
   "metadata": {},
   "source": [
    "### <p style=\"color:#F2F7A1\"> 2. Aggregate User </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b71983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_path = state_dir[1]\n",
    "state_list = os.listdir(state_path)\n",
    "agg_user_dict = {'State': [], \n",
    "                 'Year': [], \n",
    "                 'Quarter': [], \n",
    "                 'Brand': [],\n",
    "                 'Transaction_count': [], \n",
    "                 'Percentage': []\n",
    "                 }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        qtr_path = year_path + year + '/'\n",
    "        qtr_list = os.listdir(qtr_path)\n",
    "        \n",
    "        for qtr in qtr_list:\n",
    "            json_path = qtr_path + qtr\n",
    "            df = pd.read_json(json_path)\n",
    "            try:\n",
    "                for i in df['data']['usersByDevice']:\n",
    "                    brand = i['brand']\n",
    "                    count = i['count']\n",
    "                    percent = i['percentage']\n",
    "\n",
    "                    agg_user_dict['State'].append(state.replace(' And ',' and '))\n",
    "                    agg_user_dict['Year'].append(year)\n",
    "                    agg_user_dict['Quarter'].append(int(qtr[0]))\n",
    "                    agg_user_dict['Brand'].append(brand)\n",
    "                    agg_user_dict['Transaction_count'].append(count)\n",
    "                    agg_user_dict['Percentage'].append(percent)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "agg_user_df = pd.DataFrame(agg_user_dict)\n",
    "agg_user_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0525fb3",
   "metadata": {},
   "source": [
    "### <p style=\"color:#F2F7A1\"> 3. Map Transaction</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af634e83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_path = state_dir[2]\n",
    "state_list = os.listdir(state_path)\n",
    "\n",
    "map_tran_dict = {'State': [], \n",
    "                 'Year': [], \n",
    "                 'Quarter': [], \n",
    "                 'District': [],\n",
    "                 'Transaction_count': [], \n",
    "                 'Transaction_amount': []\n",
    "                }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        qtr_path = year_path + year + '/'\n",
    "        qtr_list = os.listdir(qtr_path)\n",
    "        \n",
    "        for qtr in qtr_list:\n",
    "            json_path = qtr_path + qtr\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for i in df['data']['hoverDataList']:\n",
    "                   \n",
    "                    district = i['name']\n",
    "                    count = i['metric'][0]['count']\n",
    "                    amount = i['metric'][0]['amount']\n",
    "                    \n",
    "                    map_tran_dict['State'].append(state.replace(' And ',' and '))\n",
    "                    map_tran_dict['Year'].append(year)\n",
    "                    map_tran_dict['Quarter'].append(int(qtr[0]))\n",
    "                    map_tran_dict['District'].append(district.removesuffix(' district').title().replace(' And ', ' and ').replace('andaman', 'Andaman'))\n",
    "                    map_tran_dict['Transaction_count'].append(count)\n",
    "                    map_tran_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "map_tran_df = pd.DataFrame(map_tran_dict)\n",
    "map_tran_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc303f10",
   "metadata": {},
   "source": [
    "### <p style=\"color:#F2F7A1\"> 4. Map User</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_dir[3]\n",
    "state_list = os.listdir(state_path)\n",
    "map_user_dict = {\n",
    "                 'State': [], 'Year': [], 'Quarter': [], 'District': [],\n",
    "                 'Registered_users': [], 'App_opens': []\n",
    "                 }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        qtr_path = year_path + year + '/'\n",
    "        qtr_list = os.listdir(qtr_path)\n",
    "        \n",
    "        for qtr in qtr_list:\n",
    "            json_path = qtr_path + qtr\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for i, j in df['data']['hoverData'].items():\n",
    "                    \n",
    "                    reg_user_count = j['registeredUsers']\n",
    "                    app_open_count = j['appOpens']\n",
    "                    \n",
    "                    # Appending to map_user_dict\n",
    "                    \n",
    "                    map_user_dict['State'].append(state.replace(' And ',' and '))\n",
    "                    map_user_dict['Year'].append(year)\n",
    "                    map_user_dict['Quarter'].append(int(qtr[0]))\n",
    "                    map_user_dict['District'].append(i.removesuffix(' district').title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    map_user_dict['Registered_users'].append(reg_user_count)\n",
    "                    map_user_dict['App_opens'].append(app_open_count)\n",
    "            except:\n",
    "                pass\n",
    "map_user_df = pd.DataFrame(map_user_dict)\n",
    "map_user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf62dd6",
   "metadata": {},
   "source": [
    "### <p style=\"color:#F2F7A1\"> 5.Top Transaction District-wise</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473eb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_dir[4]\n",
    "state_list = os.listdir(state_path)\n",
    "top_tran_dist_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [], 'District': [],\n",
    "                        'Transaction_count': [], 'Transaction_amount': []\n",
    "                        }\n",
    "for state in state_list:\n",
    "    year_path=state_path+ f'/{state}/'\n",
    "    year_list=os.listdir(year_path)\n",
    "\n",
    "    for year in year_list:\n",
    "        qtr_path=year_path+f'/{year}/'\n",
    "        qtr_list=os.listdir(qtr_path)\n",
    "    \n",
    "        for qtr in qtr_list:\n",
    "            json_path=qtr_path+qtr\n",
    "            df=pd.read_json(json_path)\n",
    "            try:\n",
    "                for i in df['data']['districts']:\n",
    "                    name=i['entityName']\n",
    "                    count=i['metric']['count']\n",
    "                    amount=i['metric']['amount']\n",
    "                    \n",
    "                    top_tran_dist_dict['State'].append(state.replace(' And ',' and '))\n",
    "                    top_tran_dist_dict['Year'].append(year)\n",
    "                    top_tran_dist_dict['Quarter'].append(int(qtr[0]))\n",
    "                    top_tran_dist_dict['District'].append(name.title().replace('And','and' ).replace( 'andaman','Andaman'))\n",
    "                    top_tran_dist_dict['Transaction_count'].append(count)\n",
    "                    top_tran_dist_dict['Transaction_amount'].append(amount)\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "top_tran_dist_df=pd.DataFrame(top_tran_dist_dict)\n",
    "top_tran_dist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a44adbf",
   "metadata": {},
   "source": [
    "### <p style=\"color:#F2F7A1\"> 6.Top Transaction Pincode-wise</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e225c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_dir[4]\n",
    "state_list = os.listdir(state_path)\n",
    "top_tran_pin_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [], 'Pincode': [],\n",
    "                        'Transaction_count': [], 'Transaction_amount': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path=state_path+ f'/{state}/'\n",
    "    year_list=os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        qtr_path=year_path + f'{year}/'\n",
    "        qtr_list=os.listdir(qtr_path)\n",
    "        \n",
    "        for qtr in qtr_list:\n",
    "            json_path= qtr_path+qtr\n",
    "            df=pd.read_json(json_path)\n",
    "            \n",
    "            for i in df['data']['pincodes']:\n",
    "                name = i['entityName']\n",
    "                count=i['metric']['count']\n",
    "                amount=i['metric']['amount']\n",
    "                \n",
    "                try:\n",
    "                    top_tran_pin_dict[ 'State'].append(state.replace(' And ',' and '))\n",
    "                    top_tran_pin_dict[ 'Year'].append(year)\n",
    "                    top_tran_pin_dict[ 'Quarter'].append(int(qtr[0]))\n",
    "                    top_tran_pin_dict[ 'Pincode'].append(name)\n",
    "                    top_tran_pin_dict[ 'Transaction_count'].append(count)\n",
    "                    top_tran_pin_dict[ 'Transaction_amount'].append(amount)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "top_tran_pin_df=pd.DataFrame(top_tran_pin_dict)\n",
    "top_tran_pin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472af763",
   "metadata": {},
   "source": [
    "### <p style=\"color:#F2F7A1\"> 7.Top User District-wise</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d0321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_path = state_dir[5]\n",
    "state_list = os.listdir(state_path)\n",
    "top_user_dist_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [],\n",
    "                        'District': [], 'Registered_users': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path=state_path+f'/{state}/'\n",
    "    year_list=os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        qtr_path=year_path+f'{year}/'\n",
    "        qtr_list=os.listdir(qtr_path)\n",
    "        \n",
    "        for qtr in qtr_list:\n",
    "            json_path=qtr_path+qtr\n",
    "            df=pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for i in df['data']['districts']:\n",
    "                    name=i['name']\n",
    "                    count=i['registeredUsers']\n",
    "                    \n",
    "                    top_user_dist_dict['State'].append(state.replace(' And ',' and '))\n",
    "                    top_user_dist_dict['Year'].append(year)\n",
    "                    top_user_dist_dict['Quarter'].append(int(qtr[0]))   \n",
    "                    top_user_dist_dict['District'].append(name.title().replace(' And ',' and '))\n",
    "                    top_user_dist_dict['Registered_users'].append(count)\n",
    "            except:\n",
    "                pass\n",
    "                    \n",
    "top_user_dist_df=pd.DataFrame(top_user_dist_dict)\n",
    "top_user_dist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a636a7f5",
   "metadata": {},
   "source": [
    "### <p style=\"color:#F2F7A1\"> 8.Top User Pincode-wise</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dff6a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state_path = state_dir[5]\n",
    "state_list = os.listdir(state_path)\n",
    "top_user_pin_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [],\n",
    "                        'Pincode': [], 'Registered_users': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path+f'/{state}/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        qtr_path = year_path+f'{year}/'\n",
    "        qtr_list = os.listdir(qtr_path)\n",
    "        \n",
    "        for qtr in qtr_list:\n",
    "            json_path = qtr_path + qtr\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for i in df['data']['pincodes']:\n",
    "                    \n",
    "                    name = i['name']\n",
    "                    count = i['registeredUsers']\n",
    "                    \n",
    "                    # Appending to top_user_pin_dict\n",
    "                    \n",
    "                    top_user_pin_dict['State'].append(state.replace(' And ',' and '))\n",
    "                    top_user_pin_dict['Year'].append(year)\n",
    "                    top_user_pin_dict['Quarter'].append(int(qtr[0]))\n",
    "                    top_user_pin_dict['Pincode'].append(name)\n",
    "                    top_user_pin_dict['Registered_users'].append(count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_user_pin_df = pd.DataFrame(top_user_pin_dict)\n",
    "top_user_pin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e77ef",
   "metadata": {},
   "source": [
    "## <p style=\"color:#FEC260\"> List of created dataframes</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5630672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df for df in globals() if isinstance(globals()[df], pd.core.frame.DataFrame) and df.endswith('_df')]\n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30061a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_suffix_to_districts(df):\n",
    "    if 'District' in df.columns and 'State' in df.columns:\n",
    "        delhi_df = df[df['State'] == 'Delhi']\n",
    "        \n",
    "        districts_to_suffix = [d for d in delhi_df['District'].unique() if d != 'Shahdara']\n",
    "        \n",
    "        df.loc[(df['State'] == 'Delhi') & (df['District'].isin(districts_to_suffix)), 'District'] = df.loc[(df['State'] == 'Delhi') & (df['District'].isin(districts_to_suffix)), 'District'].apply(lambda x: x + ' Delhi' if 'Delhi' not in x else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    add_suffix_to_districts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba5ecd",
   "metadata": {},
   "source": [
    "## <p style=\"color:#FEC260\"> Adding Latitude and Longitude columns</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256f391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lat_long_df = pd.read_csv(r\"E:\\Technology\\Python Project\\Clone\\Pulse\\Lat_long.csv\")\n",
    "\n",
    "for i in df_list:\n",
    "    df = globals()[i]\n",
    "    if 'District' in df.columns:\n",
    "        df = pd.merge(df, lat_long_df, on=['State', 'District'], how='left',suffixes=('_left', '_right'))\n",
    "        globals()[i] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626e41c",
   "metadata": {},
   "source": [
    "## <p style=\"color:#FEC260\"> Adding Region column to all dataframes</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32025c0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_region_column(df):\n",
    "    state_groups = {\n",
    "        'Northern Region': ['Jammu and Kashmir', 'Himachal Pradesh', 'Punjab', 'Chandigarh', 'Uttarakhand', 'Ladakh', 'Delhi', 'Haryana'],\n",
    "        'Central Region': ['Uttar Pradesh', 'Madhya Pradesh', 'Chhattisgarh'],\n",
    "        'Western Region': ['Rajasthan', 'Gujarat', 'Dadra and Nagar Haveli and Daman and Diu', 'Maharashtra'],\n",
    "        'Eastern Region': ['Bihar', 'Jharkhand', 'Odisha', 'West Bengal', 'Sikkim'],\n",
    "        'Southern Region': ['Andhra Pradesh', 'Telangana', 'Karnataka', 'Kerala', 'Tamil Nadu', 'Puducherry', 'Goa', 'Lakshadweep', 'Andaman and Nicobar Islands'],\n",
    "        'North-Eastern Region': ['Assam', 'Meghalaya', 'Manipur', 'Nagaland', 'Tripura', 'Arunachal Pradesh', 'Mizoram']\n",
    "    }\n",
    "    \n",
    "    df['Region'] = df['State'].map({state: region for region, states in state_groups.items() for state in states})\n",
    "    return df\n",
    "\n",
    "for i in df_list:\n",
    "    df = globals()[i]\n",
    "    add_region_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fbfacb",
   "metadata": {},
   "source": [
    "## <p style=\"color:#FEC260\"> Columnwise null-count and duplicated_rows-count</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4915b",
   "metadata": {},
   "source": [
    "## <b><div style='padding:20px;background-color:#d9ecd0;color:black;border-radius:4px;font-size:110%;text-align: center'>Columnwise null-count and duplicated_rows-count</div></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b7551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df_list:\n",
    "    df = globals()[i]\n",
    "    print(f\"{i}:\")\n",
    "    print(f\"Null count: \\n{df.isnull().sum().sum()}\")\n",
    "    columns_to_exclude = [col for col in df.columns if isinstance(df[col][0], list)]\n",
    "    columns_to_check = [col for col in df.columns if col not in columns_to_exclude]\n",
    "    print(f\"Duplicated rows count: \\n{df[columns_to_check].duplicated().sum()}\")\n",
    "    print(df.shape)\n",
    "    print(\"\\n\", 25 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86bd10e",
   "metadata": {},
   "source": [
    "Understanding the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1cb8c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df_list:\n",
    "    df = globals()[i]\n",
    "    print(f'{i}:\\n')\n",
    "    df.info()\n",
    "    print(\"\\n\", 45 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ca30c",
   "metadata": {},
   "source": [
    "## <p style=\"padding:25px;background-color:#DFCFBE;color:black;text-align: center\"> Dropping rows with null values </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b92328",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tran_pin_df.dropna(axis='index',inplace=True)\n",
    "top_tran_pin_df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24117cb5",
   "metadata": {},
   "source": [
    "## <p style=\"padding:25px;background-color:#DFCFBE;color:black;text-align:center\"> Changing datatype across all dataframes\n",
    " </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a516130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    try:\n",
    "        df['Year'] = df['Year'].astype('int32')\n",
    "        df['Quarter']=df['Quarter'].astype('int32')\n",
    "        df['Transaction_count']=df['Transaction_count'].astype('int32')\n",
    "        df['Registered_users']=df['Registered_users'].astype('int32')\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6604a9",
   "metadata": {},
   "source": [
    "## <p style=\"padding:25px;background-color:#DFCFBE;color:black;text-align:center\"> Outlier(s) count across all dataframes\n",
    " </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e30123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00dd512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outliers(df):\n",
    "    outliers = {}\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        if col in ['Transaction_count', 'Transaction_amount']:\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            upper_bound = q3 + (1.5 * iqr)\n",
    "            lower_bound = q1 - (1.5 * iqr)\n",
    "            outliers[col] = len(df[(df[col] > upper_bound) | (df[col] < lower_bound)])\n",
    "        else:\n",
    "            continue\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe89b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('OUTLIER COUNT ACROSS DATAFRAMES:\\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    outliers = count_outliers(df)\n",
    "    if len(outliers) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        print(df_name, \":\\n\\n\", outliers, \"\\n\")\n",
    "        print(\"\\n\", 55 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732de1c8",
   "metadata": {},
   "source": [
    "## <p style=\"padding:25px;background-color:#DFCFBE;color:black;text-align:center\"> Unique value count across all dataframes </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fff9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_value_count(df, exclude_cols=[]):\n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "        unique_vals = df[col].nunique()\n",
    "        print(f\"{col}: {unique_vals} unique values\")\n",
    "        if unique_vals < 10:\n",
    "            print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a847b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('UNIQUE VALUE COUNT ACROSS DATAFRAMES; \\n')\n",
    "for i in df_list:\n",
    "    df = globals()[i]\n",
    "    print(i, \":\\n\")\n",
    "    unique_value_count(df, exclude_cols = ['State', 'Year', 'Quarter', 'Percentage'])\n",
    "    print(\"\\n\", 55 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95b3d8",
   "metadata": {},
   "source": [
    "## <p style=\"padding:25px;background-color:#DFCFBE;color:black;text-align:center\"> Creating CSV files out of the refined dataframes </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e2c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dfs_as_csv(df_list):\n",
    "    subfolder = 'E:\\Technology\\Python Project\\Clone\\Pulse\\data\\Refined_data'\n",
    "    if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "        \n",
    "    for i in df_list:\n",
    "        df = globals()[i]\n",
    "        file_path = os.path.join(subfolder, i.replace('_df', '') + '.csv')\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a421eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dfs_as_csv(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e831a42",
   "metadata": {},
   "source": [
    "## <p style=\"padding:25px;background-color:#DFCFBE;color:black;text-align:center\"> SQL part </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce9cd4",
   "metadata": {},
   "source": [
    "## <p style=\"padding:15px;background-color:#55B4B0;color:black;text-align:center\"> Creating df as Dict so we can use it to map table name</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfafb012",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_dict={'agg_tran':agg_tran_df,\n",
    "'agg_user':agg_user_df,\n",
    "'map_tran':map_tran_df,\n",
    "'map_user':map_user_df,\n",
    "'top_tran_dist':top_tran_dist_df,\n",
    "'top_tran_pin':top_tran_pin_df,\n",
    "'top_user_dist':top_user_dist_df,\n",
    "'top_user_pin': top_user_pin_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7da8e7",
   "metadata": {},
   "source": [
    "## <p style=\"padding:15px;background-color:#55B4B0;color:black;text-align:center\"> Defining function to create DB in SQL and load data to SQL</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_into_SQL(DB_name,dfs_dict,con_str):\n",
    "    try:\n",
    "        engine = create_engine(f'{con_str}', pool_pre_ping=True)\n",
    "        con=engine.connect()\n",
    "        result=con.execute(text(f\"SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA WHERE SCHEMA_NAME = '{DB_name}'\")).fetchone()\n",
    "        if result is None:\n",
    "            con.execute(text(f\"CREATE DATABASE {DB_name}\"))\n",
    "            print(f\"Database {DB_name} Created \\n\")\n",
    "        else:\n",
    "            print(f\"Database {DB_name} exists \\n\")\n",
    "    finally:\n",
    "        con.execute(text(f\"use {DB_name}\"))\n",
    "    con_str = f'{con_str}/{DB_name}'\n",
    "    engine = create_engine(con_str, pool_pre_ping=True)\n",
    "    for table_name,df in dfs_dict.items():\n",
    "       df.to_sql(name=table_name, con=engine, if_exists='replace', index=False)\n",
    "       print(f'Data Frame {table_name} loaded into MySQL')\n",
    "    con.close()\n",
    "    engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0f0969",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_str = 'mysql+pymysql://root:Sansuganyas%4022@localhost:3306'\n",
    "push_into_SQL('phonepe_pulse',dfs_dict,con_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b252611c",
   "metadata": {},
   "source": [
    "## <p style=\"padding:15px;background-color:#55B4B0;color:black;text-align:center\"> comparing shape of tables and dataframes for accuracy</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c083f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "con=engine.connect()\n",
    "tables= con.execute(text('show tables')).fetchall()\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    row_count=con.execute(text(f\"SELECT COUNT(*) FROM {table_name}\")).fetchone()[0]\n",
    "    column_count =  con.execute(text(f\"SELECT COUNT(*) FROM information_schema.columns WHERE table_name='{table_name}'\")).fetchone()[0]\n",
    "    \n",
    "    df = dfs_dict[table_name]\n",
    "    if df.shape == (row_count,column_count):\n",
    "        print(f\"{table_name} table has {row_count} rows and {column_count} columns and shape matches DataFrame.\")\n",
    "    else:\n",
    "        print(f\"{table_name} table has {row_count} rows and {column_count} columns but shape does not match DataFrame.\")\n",
    "con.close()\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5bf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de71a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "agg_trans_df = pd.read_csv(r'E:\\Technology\\Python Project\\Clone\\Pulse\\data\\Refined_data\\agg_tran.csv')\n",
    "\n",
    "agg_trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11321dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "\n",
    "def show_detailed_report(df):\n",
    "    pr = pandas_profiling.ProfileReport(df, config_file=r'C:\\Users\\sansu\\PonePe_Pulse\\custom_config.yaml')\n",
    "    return pr.to_html()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+pymysql://root:Sansuganyas%4022@localhost:3306/phonepe_pulse')\n",
    "con=engine.connect()\n",
    "result =con.execute(text('show tables')).fetchall()\n",
    "for i in result:\n",
    "    tb_name=i[0\\]\n",
    "    str(i)=con.execute(text(f'select * from {i}')).fetchall()\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170970cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "# import pymysql\n",
    "\n",
    "def acces_sqldb(table):\n",
    "    engine = create_engine('mysql+pymysql://root:Sansuganyas%4022@localhost:3306/phonepe_pulse')\n",
    "    con=engine.connect()\n",
    "    result =con.execute(text(f'select * from {table}')).fetchall()\n",
    "    table=pd.DataFrame(result)\n",
    "    con.close()\n",
    "    engine.dispose()\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "def fetch_create_df(db_name,db_cond_substring):\n",
    "    engine = create_engine(f'mysql+pymysql://root:Sansuganyas%4022@localhost:3306/{db_name}')\n",
    "    con=engine.connect()\n",
    "    result =con.execute(text('show tables')).fetchall()\n",
    "    for i in result:\n",
    "        tb=i[0]\n",
    "        if any(sub in tb for sub in db_cond_substring):\n",
    "            data=con.execute(text(f'select * from {tb}')).fetchall()\n",
    "            df=pd.DataFrame(data)\n",
    "            print(tb)\n",
    "            globals()[tb]=df\n",
    "        else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_tran\n",
      "agg_user\n",
      "map_tran\n",
      "map_user\n",
      "top_tran_dist\n",
      "top_tran_pin\n",
      "top_user_dist\n",
      "top_user_pin\n"
     ]
    }
   ],
   "source": [
    "fetch_create_df(\"Phonepe_Pulse\",[\"user\",\"tran\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Transaction_type</th>\n",
       "      <th>Transaction_count</th>\n",
       "      <th>Transaction_amount</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Recharge &amp; bill payments</td>\n",
       "      <td>4200</td>\n",
       "      <td>1.845307e+06</td>\n",
       "      <td>Southern Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Peer-to-peer payments</td>\n",
       "      <td>1871</td>\n",
       "      <td>1.213866e+07</td>\n",
       "      <td>Southern Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Merchant payments</td>\n",
       "      <td>298</td>\n",
       "      <td>4.525072e+05</td>\n",
       "      <td>Southern Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>33</td>\n",
       "      <td>1.060142e+04</td>\n",
       "      <td>Southern Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Others</td>\n",
       "      <td>256</td>\n",
       "      <td>1.846899e+05</td>\n",
       "      <td>Southern Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Merchant payments</td>\n",
       "      <td>245111000</td>\n",
       "      <td>1.767046e+11</td>\n",
       "      <td>Eastern Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Peer-to-peer payments</td>\n",
       "      <td>240347041</td>\n",
       "      <td>7.970548e+11</td>\n",
       "      <td>Eastern Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Recharge &amp; bill payments</td>\n",
       "      <td>58950434</td>\n",
       "      <td>3.478924e+10</td>\n",
       "      <td>Eastern Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>327537</td>\n",
       "      <td>3.174670e+08</td>\n",
       "      <td>Eastern Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>Others</td>\n",
       "      <td>581674</td>\n",
       "      <td>4.489893e+08</td>\n",
       "      <td>Eastern Region</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3954 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            State  Year  Quarter          Transaction_type  \\\n",
       "0     Andaman and Nicobar Islands  2018        1  Recharge & bill payments   \n",
       "1     Andaman and Nicobar Islands  2018        1     Peer-to-peer payments   \n",
       "2     Andaman and Nicobar Islands  2018        1         Merchant payments   \n",
       "3     Andaman and Nicobar Islands  2018        1        Financial Services   \n",
       "4     Andaman and Nicobar Islands  2018        1                    Others   \n",
       "...                           ...   ...      ...                       ...   \n",
       "3949                  West Bengal  2023        2         Merchant payments   \n",
       "3950                  West Bengal  2023        2     Peer-to-peer payments   \n",
       "3951                  West Bengal  2023        2  Recharge & bill payments   \n",
       "3952                  West Bengal  2023        2        Financial Services   \n",
       "3953                  West Bengal  2023        2                    Others   \n",
       "\n",
       "      Transaction_count  Transaction_amount           Region  \n",
       "0                  4200        1.845307e+06  Southern Region  \n",
       "1                  1871        1.213866e+07  Southern Region  \n",
       "2                   298        4.525072e+05  Southern Region  \n",
       "3                    33        1.060142e+04  Southern Region  \n",
       "4                   256        1.846899e+05  Southern Region  \n",
       "...                 ...                 ...              ...  \n",
       "3949          245111000        1.767046e+11   Eastern Region  \n",
       "3950          240347041        7.970548e+11   Eastern Region  \n",
       "3951           58950434        3.478924e+10   Eastern Region  \n",
       "3952             327537        3.174670e+08   Eastern Region  \n",
       "3953             581674        4.489893e+08   Eastern Region  \n",
       "\n",
       "[3954 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_tran"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
